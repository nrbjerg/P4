I dette afsnit fremlægges den grundlæggende teori, som benyttes til at beskrive udfaldene af stokastiske eksperimenter, det vil sige eksperimenter med tilfældige udfald. Afsnittet tager udgangspunkt i \cite{sandsynlighedsBog}.
%def 1.1 og 1.2
\begin{defn}
Mængden af de mulige udfald $S$ af et stokastisk eksperiment kaldes \textbf{udfaldsrummet} af eksperimentet.\\
En delmængde af udfaldsrummet $A\subseteq S$ kaldes en \textbf{hændelse}.
\end{defn}

En hændelse kan noteres med et prædikat $q(s)$ på følgende vis
\begin{align*}
    \left\{q(s)\right\} = \Set*{s\in S\given q(s)}
\end{align*}
%hvor $S$ er udfaldsrummet. Eksempelvis kan der skrives $\{\text{Det regner i morgen}\}$ for at beskrive hændelsen, hvor netop dette gør sig gældende.
\begin{exmp}
Lad $V_{regn}$ betegne en dag med regn og $V_{sol}$ betegne en dag med sol. Udfaldsrummet for vejret i weekenden kan opstilles som mængden:
\begin{equation*}
    S = \{(V_{regn}, V_{sol}), (V_{regn}, V_{regn}), (V_{sol}, V_{sol}), (V_{sol}, V_{regn})\}
\end{equation*}
Så er hændelsen $\left\{\text{Solen skinner lørdag}\right\}$ givet ved
\begin{equation*}
    \left\{\text{Solen skinner lørdag}\right\} = \Set*{x \in S \given x_1 = V_{sol}} = \left\{(V_{sol}, V_{sol}), (V_{sol}, V_{regn})\right\}%x_1 er første indgang i tuplen
\end{equation*}
\end{exmp}

%def 1.3
\begin{defn} [Aksiomer for sandsynlighed] \label{def:axiomsOfPropability}
Lad $S$ være udfaldsrummet af et stokastisk eksperiment.
Et \textbf{sandsynlighedsmål} er en funktion $P$, som til hver hændelse $A \subseteq S$ tildeler et reelt tal $P(A) \in [0; 1]$, hvor $P(A)$ kaldes \textbf{sandsynligheden} for $A$. \\
For $P$ gælder:
\begin{enumerate}
    \item $P(S)=1$
    \item hvis $A_1,A_2,\ldots\subseteq S$ hvor $i \neq j \implies A_i\cap A_j=\emptyset$, så er 
    \begin{equation*}
        P\left(\bigcup_{k=1}^\infty A_k\right)=\sum_{k=1}^\infty P(A_k)
    \end{equation*} \label{enu:axiomsOfPropability2}
\end{enumerate}
\end{defn}

Punkt \ref{enu:axiomsOfPropability2} gælder også i tilfældet med endlige mange hændelser, hvilket proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening} viser. 

\begin{prop} \label{cor:sandsynlighedenAfEnEndeligDijunktForening} % Prop 1.2
Lad P være et sandsynlighedsmål, så gælder det, at $P(\emptyset) = 0$. Hvis $A_1, \ldots , A_n \subseteq S$ således $A_i\cap A_j=\emptyset$, for $i \neq j$, så er
\begin{equation*}
    P\left(\bigcup^n_{k = 1} A_k\right) = \sum^n_{k = 1} P(A_k)
\end{equation*}
\end{prop}
\begin{proof}
Lad $B_1 = S$ og $B_k = \emptyset$ for alle $k \geq 2$, så er $B_i \cap B_j = \emptyset$ for alle $i \neq j$, hvilket medfører at \begin{equation*}
    P(S) = P\left(\bigcup^\infty_{k = 1} B_k\right) = \sum^\infty_{k = 1} P(B_k) = P(B_1) + \sum^\infty_{k = 2} P(B_k) = 1 + \sum^\infty_{k = 2} P(\emptyset) 
\end{equation*}
Eftersom $P(S) = 1$, følger det, at $\sum^\infty_{k = 2} P(\emptyset) = 0$, hvilket medfører, at $P(\emptyset) = 0$. \\
Lad $k\in \N$ og $A_k = \emptyset$ for alle $k > n$. Så er $A_i \cap A_j = \emptyset$ for alle $i \neq j$ og vi har derfor 
\begin{equation*}
    P\left(\bigcup_{k=1}^\infty A_k\right)=\sum_{k=1}^\infty P(A_k)
\end{equation*}
Vi har, at $P(A_k) = 0$ for alle $k > n$, og $\displaystyle\left(\bigcup^n_{k = 1} A_k\right) \cup \emptyset = \bigcup^n_{k = 1} A_k$, hvilket medfører, at
\begin{equation*}
   P\left(\bigcup_{k=1}^n A_k\right) = P\left(\bigcup_{k=1}^\infty A_k\right) = \sum_{k=1}^\infty P(A_k) = \sum_{k=1}^n P(A_k)
\end{equation*}
\end{proof} 
Proposition \ref{prop:sandsynlighedMedToHændelser} beskriver grundlæggende egenskaber, der gælder for hændelser. 
\begin{prop} \label{prop:sandsynlighedMedToHændelser} % Prop 1.3
Lad $P$ være et sandsynlighedsmål og lad $A, B \subseteq S$, så er 
\begin{enumerate}
    \item $P(A^c) = 1 - P(A)$ \label{enu:propsandsynlighedMedToHændelser1}
    \item $P(A\backslash B) = P(A) - P(A \cap B)$ 
    \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ 
    \item Hvis $A \subseteq B$, så er $P(A) \leq P(B)$
\end{enumerate}
\end{prop}
\begin{proof}
\ % Enumerate spacing
\begin{enumerate}
    \item Vi har $S=A \cup A^c$ og $A \cap A^c=\emptyset$. Ved at benytte proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening} følger det, at 
\begin{align*}
    P(S)=P(A \cup A^c) = P(A) + P(A^c) = 1
\end{align*}
Heraf følger det, at $P(A^c) = 1 - P(A)$.
    
    \item Bemærk, at $A = (A \cap B) \cup (A \backslash B)$ er en disjunkt forening. Vi kan derfor benytte proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening}, til at skrive
    $P(A) = P(A \cap B) + P(A \backslash B)$, det følger heraf, at $P(A \backslash B) = P(A) - P(A \cap B)$.
    
    \item Bemærk, at $A\cup B=A\cup (B\backslash A)$ og $A\cap (B \backslash A)=\emptyset$, i henhold til proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening} gælder det derfor, at
    \begin{align*}
        P(A\cup B) = P(A \cup (B \backslash A) = P(A)+P(B\backslash A)=P(A)+P(B)-P(A\cap B).
    \end{align*}
    
    \item Lad $A \subseteq B$. I henhold til del 2 af propositionen er $P(B) = P(B \cap A) + P(B \backslash A)$, men da $A \subseteq B$ er $B \cap A = A$. Det følger derfor, at $P(B) = P(A) + P(B \backslash A) \geq P(A)$, da $P(B \backslash A) \geq 0$, jævnfør definition \ref{def:axiomsOfPropability}.
\end{enumerate}
\end{proof}


 
\begin{exmp} % exmp 1.10 (ish)
Vælg et tilfældigt $n \in \{1, 2 \ldots, 10\}$, med sandsynlighed $P(n)=\frac{1}{10}$. Hvad er sandsynligheden for at $2$ eller $3$ er en divisor af $n$?
Vi introducerer hændelserne
\begin{equation*}
    A_k = \{k \text{ er en divisor af } n\} \text{ for } k = 1, \ldots, 10  
\end{equation*}
Vi vil altså finde sandsynligheden $P(A_2 \cup A_3)$. Vi ved, at $P(A_2) = \frac{1}{2}$ og $P(A_3) = \frac{3}{10}$, men de to hændelser er ikke disjunkte, vi benytter derfor proposition \ref{prop:sandsynlighedMedToHændelser}, og opnår:
\begin{equation*}
    P(A_2 \cup A_3) = P(A_2) + P(A_3) - P(A_2 \cap A_3) = P(A_2) + P(A_3) - P(A_6)
\end{equation*}
da $P(A_6) = \frac{1}{10}$ følger det heraf, at $P(A_2 \cup A_3) = \frac{1}{2} + \frac{3}{10} - \frac{1}{10} = \frac{7}{10}$.
\end{exmp}


Ofte er der sammenhænge imellem hændelser. Det kunne for eksempel være at der er større sandsynlighed for at det regner søndag, hvis det har regnet lørdag, end hvis det var tørvejr lørdag.
\begin{defn}\label{def:betingethændelse} %def 1.4
Lad $A, B$ være hændelser og lad $P(B)>0$. Sandsynligheden for en \textbf{betinget hændelse} noteres ved
\begin{align*}
    P(A|B)=\frac{P(A\cap B)}{P(B)}
\end{align*}
\end{defn}
Sandsynligheden $P(A|B)$ forståes som sandsynligheden for $A$ givet hændelsen $B$.

 
\begin{thm}[Bayes sætning]\label{thm:bayesTheorem} %prop 1.11
Lad $A, B \subseteq S$ samt $P(A), P(B) > 0$, det gælder at
\begin{align*}
    P(A|B)P(B)=P(B|A)P(A)
\end{align*}
\end{thm}
\begin{proof}
Ud fra definition \ref{def:betingethændelse} kan det udledes, at $P(A|B)P(B)=P(A\cap B)=P(B|A)P(A)$
\end{proof}

\begin{lem} [Distributiv lov for uendlige foreningsmængder] \label{lem:DistributiveLawForInfiniteUnions}
Lad $A \subseteq S$ og $B_1, B_2, \ldots \subseteq S$. Så er 
\begin{equation*}
    A \cap \left( \bigcup^\infty_{k = 1} B_k \right) = \bigcup^\infty_{k = 1} (A \cap B_k)
\end{equation*}
\end{lem}
\begin{proof}
Antag at $x \in A \cap \left( \bigcup^\infty_{k = 1} B_k\right)$, så er $x \in A$ og $x \in \bigcup^\infty_{k = 1} B_k$, der eksisterer altså et $n \in \N$ således $x \in B_n$, altså er $x \in A \cap B_n \subseteq \bigcup^\infty_{k = 1} (A \cap B_k)$. 
Hvis $x \in \bigcup^\infty_{k = 1} (A \cap B_k)$, eksisterer et $n \in \N$, således $x \in (A \cap B_n)$. det vil sige, at $x \in B_n \subseteq \bigcup^\infty_{k = 1} B_k$ og $x \in A$ så $x \in A \cap \left( \bigcup^\infty_{k = 1} B_k \right)$. Vi har altså $A \cap \left( \bigcup^\infty_{k = 1} B_k \right) = \bigcup^\infty_{k = 1} (A \cap B_k)$.
\end{proof}

Lemmaet giver os mulighed for at formulere følgende resultat, som er kendt som loven om total sandsynlighed.
\begin{thm} [Loven om total sandsynlighed]\label{thm:LPT}
Lad $B_1, B_2, \ldots$ være disjunkte hændelser med $P(B_k) > 0$ for $k \in \N$ og $S = \bigcup^\infty_{k = 1} B_k$, så er
\begin{equation*}
    P(A) = \sum^\infty_{k = 1} P(A | B_k)P(B_k)
\end{equation*}
for alle $A \subseteq S$
\end{thm}
\begin{proof}
Vi har lighederne:
\begin{equation*}
    A = A \cap S = A \cap \left( \bigcup^\infty_{k = 1} B_k \right) = \bigcup^\infty_{k = 1} (A \cap B_k)
\end{equation*}
jævnfør lemma \ref{lem:DistributiveLawForInfiniteUnions}. Eftersom $(A \cap B_i) \cap (A \cap B_j) = \emptyset$ for $i \neq j$ og $P(A \cap B_k) = P(A | B_k) P(B_k)$ per definitionen af sandsynligheden af en betinget hændelse, gælder lighederne
\begin{equation*}
    P(A) = P\left( \bigcup^\infty_{k = 1} A \cap B_k\right)= \sum^\infty_{k = 1} P(A \cap B_k) = \sum^\infty_{k = 1} P(A | B_k)P(B_k)
\end{equation*}
\end{proof}

To hændelser kan ske uafhængigt af hinanden. Dette kan eksempelvis være, hvis man kaster en terning, så vil sandsynligheden for $1$ være $\frac{1}{6}$. Tidligere på dagen blev terningen kastet en gang til $1$. Hændelserne har ingen effekt på hinandens udkom, så er den betinget hændelse stadig den samme. Lad $A=$\{Antallet af $1$'er slået i næste kast\} og $B=$\{Antallet af $1$'er slået tidligere\}, så er $P(A)=P(A|B)$, hvor den ubetinget og betinget sandsynlighed er den samme.  Da $P=P(A|B)$, er  $P(A\cap B)=P(A)P(B)$. 
\begin{defn}[Parvis uafhængige hændelser] \label{Def:def1.5} %Def 1.5
Hvis $A, B \subseteq S$ og det gælder at
\begin{align*}
    P(A\cap B)=P(A)P(B),
\end{align*}
så kaldes hændelserne \textbf{parvise uafhængige}.
\end{defn}
Hvis to hændelser ikke er parvis uafhængige, kaldes de parvis afhængige.

Ud fra definition \ref{Def:def1.5} kan der udledes en sammenhæng mellem den betinget sandsynlighed og sandsynligheden for den enekelte hændelse. 
\begin{cor} %Cor 1.4
    Lad $A$ og $B$ være hændelser, og $P(B) > 0$, så er $P(A)=P(A|B)$, hvis og kun hvis $A$ og $B$ er parvis uafhængige.   
\end{cor}
\begin{proof}
Lad $A$ og $B$ være uafhængige hændelser, så gælder det, at 
\begin{align*}
    P(A\cap B)=P(A)P(B)
\end{align*}
Ud fra definition \ref{def:betingethændelse} gælder, at 
\begin{align*}
    P(A|B)=\frac{P(A\cap B)}{P(B)} =\frac{P(A)P(B)}{P(B)}=P(A)
\end{align*}
Da der er tale om ligheder, gælder biimplikationen.
\end{proof}

\begin{exmp} \label{exp:terning}
En terning kastes to gange, vi definerer følgende hændelser
\begin{align*}
  A_1 &=\{6 \text{ ved første kast}\} \\ A_2 &= \{6 \text{ ved andet kast}\} 
\end{align*}
med $P(A_1) = P(A_2) = \frac{1}{6}$. Sandsynligheden for at slå to seksere er $P(A_1 \cap A_2)=\frac{1}{36}$, da det første terningkast ikke påvirker det næste, og der er $6$ forskellige udfald i de to kast. Heraf følger det, at de to hændelser er parvis uafhængige af hinanden, da $P(A_1 \cap A_2) = P(A_1)P(A_2)$.
\end{exmp}

Vi vil nu kigge på tilfældet hvor der uendeligt mange uafhængige hændelser.
\begin{defn}
    Hændelserne $A_1, A_2, \ldots$ kaldes \textbf{uafhængige} hvis det for alle $n = 2, 3, \ldots$ og strengt voksende følge $\{i_k\}^n_{k = 1}$, hvor $i_k \in \N$ gælder at
    \begin{equation*}
        P\left(\bigcap_{k = 1}^n A_{i_k} \right) = \prod_{k = 1}^n P(A_{i_k})
    \end{equation*}
\end{defn}

%\begin{exmp}
%eksempel \ref{exp:terning} ændres til, at kaste terningen seks gange i stedet for to gange. Først defineres følgende hændelser:
%\begin{equation*}
%    A_k=\{6 \text{ ved det k'te kast}\} \text{ med } P(A_k)=1/6, \text{ for } k = 1,2\ldots,6
%\end{equation*}
%
%det gælder, at $A_k$ og $A_j$, hvor  $k\neq j$, er parvis uafhængige af hinanden
%derudover gælder det, at
%\begin{align*}
%p(\{\text{6 i alle seks kast}\}) = P\left(\bigcap_{k=1}^6 A_{k}\right)=\frac{1}{46656}=\prod_{k=1}^6 P\left(A_{k}\right)
%\end{align*}
%derfor er alle $A_k$ for $k=1,2,\ldots,6$ uafhængige af hinanden
%\end{exmp}

\begin{exmp}\label{exmp:uafhængelighed}
En terning kastes seks gange, først defineres følgende hændelser: \begin{equation*} 
    A_k=\{6 \text{ ved det k'te kast}\} \text{ med } P(A_k)=\frac{1}{6}, \text{ for } k = 1,2\ldots,6 
\end{equation*} 
Det gælder, at $A_i$ og $A_j$, hvor  $i\neq j$, er parvis uafhængige af hinanden, se eksempel \ref{exp:terning}. Lad $n \in \{1, 2, \ldots, 6\}$ og $\{i_k\}_{k = 1}^n\subseteq \N$ være en strengt voksende følge.
Da de tidligere kast ikke påvirker det nuværende kast, og da der er tale om en terning, er der $6^n$ udfald i alt, med lige stor sandsynlighed, altså er
\begin{align*}
    P\left(\bigcap_{k=1}^n A_{i_k}\right)=\frac{1}{6^n}
\end{align*}
 Men $\frac{1}{6^n} = \prod_{k=1}^n P\left(A_{i_k}\right)$ heraf følger det at $A_1, A_2, \ldots$ er uafhængige af hinanden.
\end{exmp}
