I dette afsnit fremlægges den grundlæggende teori, som benyttes til at beskrive stokastiske eksperimenter. Afsnittet tager udgangspunkt i \cite{sandsynlighedsBog}.
%def 1.1 og 1.2
\begin{defn}
Mængden af de mulige udfald $S$ af et stokastisk eksperiment kaldes \textbf{udfaldsrummet}.\\
En delmængde af udfaldsrummet $A\subseteq S$ kaldes en \textbf{hændelse}.
\end{defn}

En hændelse kan noteres med et prædikat $q(s)$ på følgende vis
\begin{align*}
    \left\{q(s)\right\} = \Set*{s\in S\given q(s)}
\end{align*}
%hvor $S$ er udfaldsrummet. Eksempelvis kan der skrives $\{\text{Det regner i morgen}\}$ for at beskrive hændelsen, hvor netop dette gør sig gældende.
Lad $V_{regn}$ betegne en dag med regn og $V_{sol}$ betegne en dag med sol. Udfaldsrummet for vejret i weekenden kan opstilles som mængden:
\begin{equation*}
    S = \{(V_{regn}, V_{sol}), (V_{regn}, V_{regn}), (V_{sol}, V_{sol}), (V_{sol}, V_{regn})\}
\end{equation*}
Så er hændelsen $\left\{\text{Solen skinner lørdag}\right\}$ givet ved
\begin{equation*}
    \left\{\text{Solen skinner lørdag}\right\} = \Set*{x \in S \given x_1 = V_{sol}} = \left\{(V_{sol}, V_{sol}), (V_{sol}, V_{regn})\right\}%x_1 er første indgang i tuplen
\end{equation*}

%def 1.3
\begin{defn} [Aksiomer for sandsynlighed] \label{def:axiomsOfPropability}
Lad $S$ være udfaldsrummet af et eksperiment og $A\subseteq S$ være en hændelse.
Et \textbf{sandsynlighedsmål} er en funktion $P$, som til hver hændelse $A$ tildeler et reelt tal $P(A) \in [0; 1]$, hvor $P(A)$ er \text{sandsynligheden} for $A$. \\ 
For $P$ gælder:
\begin{enumerate}
    \item $P(S)=1$
    \item hvis $A_1,A_2,\ldots$ hvor $i \neq j \implies A_i\cap A_j=\emptyset$, så er 
    \begin{equation*}
        P\left(\bigcup_{k=1}^\infty A_k\right)=\sum_{k=1}^\infty P(A_k)
    \end{equation*} \label{enu:axiomsOfPropability2}
\end{enumerate}
\end{defn}

Definiton \ref{def:axiomsOfPropability} punkt \ref{enu:axiomsOfPropability2} er meget brugetbart, når det kommer til at finde sandsynlighedsmålet. I definitionen ses, at det gælder for uendelige hændelser, hvilket proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening} siger det også gælder for endelige hændelser. 

\begin{prop} \label{cor:sandsynlighedenAfEnEndeligDijunktForening} % Prop 1.2
Lad P være et sandsynlighedsmål, så er
\begin{enumerate}
    \item $P(\emptyset) = 0$
    \item hvis $A_1, \ldots , A_n$ og $A_i\cap A_j=\emptyset$, for $i \neq j$, så er 
    \begin{equation*}
        P\left(\bigcup^n_{k = 1} A_k\right) = \sum^n_{k = 1} P(A_k)
    \end{equation*}
\end{enumerate}

\end{prop}
\begin{proof}
Lad $B_1 = S$ og $B_k = \emptyset$ for alle $k \geq 2$, så er $B_i \cap B_j = \emptyset$ for alle $i \neq j$, hvilket medfører at \begin{equation*}
    P(S) = P\left(\bigcup^\infty_{k = 1} B_k\right) = \sum^\infty_{k = 1} P(B_k) = P(B_1) + \sum^\infty_{k = 2} P(B_k) = 1 + \sum^\infty_{k = 2} P(\emptyset) 
\end{equation*}
Eftersom $P(S) = 1$, følger det, at $\sum^\infty_{k = 2} P(\emptyset) = 0$, men da $P(\emptyset) \geq 0$ for alle $k \geq 2$ er $P(\emptyset) = 0$. \\
Lad $k\in \N$ og $A_k = \emptyset$ for alle $k > n$. Så er $A_i \cap A_j = \emptyset$ for alle $i \neq j$ og vi har derfor 
\begin{equation*}
    P\left(\bigcup_{k=1}^\infty A_k\right)=\sum_{k=1}^\infty P(A_k)
\end{equation*}
da $P(A_k) = 0$ for alle $k > n$, og $\displaystyle\left(\bigcup^n_{k = 1} A_k\right) \cup \emptyset = \bigcup^n_{k = 1} A_k$ medfører, at
\begin{equation*}
   P\left(\bigcup_{k=1}^n A_k\right) = P\left(\bigcup_{k=1}^\infty A_k\right) = \sum_{k=1}^\infty P(A_k) = \sum_{k=1}^n P(A_k)
\end{equation*}
\end{proof} 
Proposition \ref{prop:sandsynlighedMedToHændelser} fortæller omkring nogen grundlæggende egenskaber der gælder for hændelser. 
\begin{prop} \label{prop:sandsynlighedMedToHændelser} % Prop 1.3
Lad $P$ være et sandsynlighedsmål på et udfaldsrum $S$ og lad $A, B \subseteq S$, så er 
\begin{enumerate}
    \item $P(A^c) = 1 - P(A)$ \label{enu:propsandsynlighedMedToHændelser1}
    \item $P(A\backslash B) = P(A) - P(A \cap B)$ 
    \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ 
    \item Hvis $A \subseteq B$, så er $P(A) \leq P(B)$
\end{enumerate}
\end{prop}
\begin{proof}
\ % Enumerate spacing
\begin{enumerate}
    \item Vi har $S=A \cup A^c$ og $A \cap A^c=\emptyset$. Ved at benytte proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening} følger det, at 
\begin{align*}
    P(S)=P(A \cup A^c) = P(A) + P(A^c) = 1
\end{align*}
Heraf følger det, at $P(A^c) = 1 - P(A)$.
    
    \item Bemærk, at $A = (A \cap B) \cup (A \backslash B)$ er en disjunkt forening. Vi kan derfor benytte proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening}, til at skrive
    $P(A) = P(A \cap B) + P(A \backslash B)$, det følger heraf, at $P(A \backslash B) = P(A) - P(A \cap B)$.
    
    \item Bemærk, at $A\cup B=A\cup (B\backslash A)$ og $A\cap (B \backslash A)=\emptyset$, i henhold til proposition \ref{cor:sandsynlighedenAfEnEndeligDijunktForening} gælder det derfor, at
    \begin{align*}
        P(A\cup B) = P(A \cup (B \backslash A) = P(A)+P(B\backslash A)=P(A)+P(B)-P(A\cap B).
    \end{align*}
    
    \item Lad $A \subseteq B$. I henhold til del 2 af propositionen er $P(B) = P(B \cap A) + P(B \backslash A)$, men da $A \subseteq B$ er $B \cap A = A$. Det følger derfor, at $P(B) = P(A) + P(B \backslash A) \geq P(A)$, da $P(B \backslash A) \geq 0$, jævnfør definition \ref{def:axiomsOfPropability}.
\end{enumerate}
\end{proof}


 
\begin{exmp} % exmp 1.10 (ish)
Vælg et tilfældigt $n \in \{1, 2 \ldots, 10\}$, med sandsynlighed $P(n)=\frac{1}{10}$. Hvad er sandsynligheden for at $2$ eller $3$ er en divisor af $n$?
Vi introducere hændelserne
\begin{equation*}
    A_k = \{k \text{ er en divisor af } n\} \text{ for } k = 1, \ldots, 10  
\end{equation*}
Vi vil altså finde sandsynligheden $P(A_2 \cup A_3)$, vi ved, at $P(A_2) = \frac{1}{2}$ og $P(A_3) = \frac{3}{10}$, men de to hændelser er ikke disjunkte, vi benytter derfor proposition \ref{prop:sandsynlighedMedToHændelser}, og opnår:
\begin{equation*}
    P(A_2 \cup A_3) = P(A_2) + P(A_3) - P(A_2 \cap A_3) = P(A_2) + P(A_3) - P(A_6)
\end{equation*}
da $P(A_6) = \frac{1}{10}$ følger det heraf, at $P(A_2 \cup A_3) = \frac{1}{2} + \frac{3}{10} - \frac{1}{10} = \frac{7}{10}$.
\end{exmp}


Ofte er der sammenhænge imellem hændelser, det kunne for eksempel være at der er større sandsynlighed for at det regner søndag, hvis det har regnet lørdag, end hvis det var tørvejr lørdag.
\begin{defn}\label{def:betingethændelse} %def 1.4
Lad $B$ være en hændelse samt $P(B)>0$. Sandsynligheden for en \textbf{betinget hændelse} noteres ved
\begin{align*}
    P(A|B)=\frac{P(A\cap B)}{P(B)}
\end{align*}
\end{defn}
Sandsynligheden $P(A|B)$ forståes som sandsynligheden for $A$ givet hændelsen $B$.

 
\begin{thm}[Bayes sætning] %prop 1.11
Lad $A, B \subseteq S$ samt $P(A), P(B) > 0$, det gælder at
\begin{align*}
    P(A|B)P(B)=P(B|A)P(A)
\end{align*}
\end{thm}
\begin{proof}
Ud fra definition \ref{def:betingethændelse} kan det udledes, at
\begin{align*}
    P(A|B)P(B)=P(A\cap B)=P(B|A)P(A)
\end{align*}
\end{proof}

\begin{lem} \label{lem:DistributiveLawForInfiniteUnions}
Lad $A \subseteq S$ og $B_1, B_2, \ldots \subseteq S$. Så er 
\begin{equation*}
    A \cap \left( \bigcup^\infty_{k = 1} B_k \right) = \bigcup^\infty_{k = 1} (A \cap B_k)
\end{equation*}
\end{lem}
\begin{proof}
Antag at $x \in A \cap \left( \bigcup^\infty_{k = 1} B_k\right)$, så er $x \in A$ og $x \in \bigcup^\infty_{k = 1} B_k$, der eksistere altså et $n \in \N$ således $x \in B_n$, altså er $x \in A \cap B_n \subseteq \bigcup^\infty_{k = 1} (A \cap B_k)$. 
Hvis $x \in \bigcup^\infty_{k = 1} (A \cap B_k)$, eksistere et $n \in \N$, således $x \in (A \cap B_k)$. det vil sige at $x \in B_k \subseteq \bigcup^\infty_{k = 1} B_k$ og $x \in A$ så $x \in A \cap \left( \bigcup^\infty_{k = 1} B_k \right)$.
\end{proof}


\begin{thm} \label{thm:LPT}
Lad $B_1, B_2, \ldots$ være disjunkte hændelser med $P(B_k) > 0$ for $k \in \N$ og $S = \bigcup^\infty_{k = 1} B_k$, så er
\begin{equation*}
    P(A) = \sum^\infty_{k = 1} P(A | B_k)P(B_k)
\end{equation*}
for alle $A \subseteq S$
\end{thm}
\begin{proof}
\begin{equation*}
    A = A \cap S = A \cap \left( \bigcup^\infty_{k = 1} B_k \right) = \bigcup^\infty_{k = 1} (A \cap B_k)
\end{equation*}
Jævnfør lemma \ref{lem:DistributiveLawForInfiniteUnions}. Eftersom $(A \cap B_i) \cap (A \cap B_j) = \emptyset$ for $i \neq j$, er 
\begin{equation*}
    P(A) = P\left( \bigcup^\infty_{k = 1} A \cap B_k\right)= \sum^\infty_{k = 1} P(A \cap B_k) = \sum^\infty_{k = 1} P(A | B_k)P(B_k)
\end{equation*}
da $P(A \cap B_k) = P(A | B_k) P(B_k)$ per definitionen af sandsynligheden af en betinget sandsynlighed.
\end{proof}

To hændelser kan ske uafhængigt af hinanden. Dette kan eksempelvis være, hvis man kaster en terning, så vil sandsynligheden for $1$ være $\frac{1}{6}$. Tidligere på dagen blev terningen kastet en gang til $1$. Hændelserne har ingen effekt på hinandens udkom, så er den betinget hændelse stadig den samme. Lad $A=$\{Antallet af $1$'er slået i næste kast\} og $B=$\{Antallet af $1$'er slået tidligere\}, så er $P(A)=P(A|B)$, hvor den ubetinget og betinget sandsynlighed er den samme.  Da $P=P(A|B)$, er  $P(A\cap B)=P(A)P(B)$. 
\begin{defn}[Parvis uafhængige hændelser] \label{Def:def1.5} %Def 1.5
Hvis det gælder for to hændelser $A$ og $B$, at 
\begin{align*}
    P(A\cap B)=P(A)P(B),
\end{align*}
så er hændelserne \textbf{parvise uafhængige}. 
\end{defn}
Hvis to hændelser ikke er parvis uafhængige, kaldes de parvis afhængige.

Ud fra definition \ref{Def:def1.5} kan der udledes en sammenhæng mellem den betinget sandsynlighed og sandsynligheden for den enekelte hændelse. 
\begin{cor} %Cor 1.4
    Lad $A$ og $B$ være hændelser, og $P(B) > 0$, så er $P(A)=P(A|B)$, hvis og kun hvis $A$ og $B$ er parvis uafhængige.   
\end{cor}
\begin{proof}
Lad $A$ og $B$ være uafhængige hændelser, så gælder det, at 
\begin{align*}
    P(A\cap B)=P(A)P(B)
\end{align*}
Ud fra definition \ref{def:betingethændelse} gælder, at 
\begin{align*}
    P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{P(A)P(B)}{P(B)}=P(A)
\end{align*}
Da dette også gælder den anden vej, er det hermed bevist.
\end{proof}

\begin{exmp} \label{exp:terning}
En terning kastes to gange, vi definerer følgende hændelser
\begin{align*}
  A_1 &=\{6 \text{ ved første kast}\} \\ A_2 &= \{6 \text{ ved andet kast}\} 
\end{align*}
med $P(A_1) = P(A_2) = \frac{1}{6}$. Sandsynligheden for at slå to seksere er $P(A_1 \cap A_2)=\frac{1}{36}$, da det første terningkast ikke påvirker det næste, og der er $6$ forskellige udfald i de to kast. Heraf følger det, at de to hændelser er parvis uafhængige af hinanden, da $P(A_1 \cap A_2) = P(A_1)P(A_2)$.
\end{exmp}

Vi vil nu kigge på tilfældet hvor der uendeligt mange uafhængige hændelser.
\begin{defn}
    Hændelserne $A_1, A_2, \ldots$ kaldes \textbf{uafhængige} hvis det for alle $n = 2, 3, \ldots$ og strengt voksende følge $\{i_k\}^n_{k = 1}$, hvor $i_k \in \N$ gælder at
    \begin{equation*}
        P\left(\bigcap_{k = 1}^n A_{i_k} \right) = \prod_{k = 1}^n P(A_{i_k})
    \end{equation*}
\end{defn}

%\begin{exmp}
%eksempel \ref{exp:terning} ændres til, at kaste terningen seks gange i stedet for to gange. Først defineres følgende hændelser:
%\begin{equation*}
%    A_k=\{6 \text{ ved det k'te kast}\} \text{ med } P(A_k)=1/6, \text{ for } k = 1,2\ldots,6
%\end{equation*}
%
%det gælder, at $A_k$ og $A_j$, hvor  $k\neq j$, er parvis uafhængige af hinanden
%derudover gælder det, at
%\begin{align*}
%p(\{\text{6 i alle seks kast}\}) = P\left(\bigcap_{k=1}^6 A_{k}\right)=\frac{1}{46656}=\prod_{k=1}^6 P\left(A_{k}\right)
%\end{align*}
%derfor er alle $A_k$ for $k=1,2,\ldots,6$ uafhængige af hinanden
%\end{exmp}

\begin{exmp}\label{exmp:uafhængelighed}
En terning kastes seks gange, først defineres følgende hændelser: \begin{equation*} 
    A_k=\{6 \text{ ved det k'te kast}\} \text{ med } P(A_k)=\frac{1}{6}, \text{ for } k = 1,2\ldots,6 
\end{equation*} 
Det gælder, at $A_k$ og $A_j$, hvor  $k\neq j$, er parvis uafhængige af hinanden, se eksempel \ref{exp:terning}. Lad $n \in \{1, 2, \ldots, 6\}$ og $\{i_k\}_{k = 1}^n\subseteq \N$ være en strengt voksende følge.
Da de tidligere kast ikke påvirker det nuværende kast, og da der er tale om en terning, er der $6^n$ udfald i alt, med lige stor sandsynlighed, altså er
\begin{align*}
    P\left(\bigcap_{k=1}^n A_{i_k}\right)=\frac{1}{6^n}
\end{align*}
 Men $\frac{1}{6^n} = \prod_{k=1}^n P\left(A_{i_k}\right)$ heraf følger det at $A_1, A_2, \ldots$ er uafhængige af hinanden.
\end{exmp}
