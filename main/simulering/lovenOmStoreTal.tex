\section{Loven om store tal}
\begin{theorem} \label{thm:Markovsulighed}[Markovs ulighed]
Hvis $X$ er en stokastisk variable, således
$E[X] < \infty$. Så gælder
\begin{align*}
    P(|X|\geq a) \leq \frac{E[|X|]}{a} \text{ for alle } a > 0
\end{align*}
\end{theorem}
\begin{proof}
\end{proof}
\begin{proof}
  Lad $A=\{|X|\geq a\}$, og definier indikator funktionen $I_A = 1$ hvis $A$ og $I_{A} = 0$ ellers. Vi har $|X| \geq aI_{A}$, da $aI_{A} = 0$ hvis $|X| < a$ og $a$ hvis $|X| \geq a$. Hvis den forventede værdi tages, på begge sider opnåes
  \begin{align*}
    E[|X|]\geq E[aI_A] = a E[I_A] \iff \frac{E[|X|]}{a}\geq E[I_A]
  \end{align*}
  resultatet følger heraf da $E[I_{A}] = P(A)$.
\end{proof}
Det er værd at bemærke, at hvis $a<0$ så skal relationen vendes om.

Chebyshews ulighed siger noget om, hvad sandsynligheden er for, at en stokastisk variabel ligger inden for $c$ gange standardafvigelser for middelværdien.
\begin{theorem} \label{Thm:Chebyshewsulighed}[Chebyshews ulighed]
    Lad $X$ være en stokastisk variable med middelværdien $\mu$ og variansen $\sigma^2>0$. For alle $c>0$ gælder, at
    \begin{align*}
        P(|X-\mu|\geq c \sigma)\leq \frac{1}{c^2}
    \end{align*}
\end{theorem}
\begin{proof}%fra wiki
    \begin{align*}
        P(|X-\mu|\geq c \sigma)=P((X-\mu)^2\geq c^2\sigma^2)
    \end{align*}
Ved at benytte Markovs ulighed, sætning \ref{thm:Markovsulighed} opnåes
\begin{align*}
    P((X-\mu)^2\geq c^2\sigma^2) \leq \frac{E[(X-\mu)^2]}{c^2\sigma^2}
\end{align*}
Da $E[(X-\mu)^2]$ er defineret af $\sigma^2$, så indsættes dette
\begin{align*}
    \frac{E[(X-\mu)^2]}{c^2\sigma^2} = \frac{\sigma^2}{c^2\sigma^2} = \frac{1}{c^2}
\end{align*}
Hvilket afslutter beviset.
\end{proof}

\begin{definition}
  Lad $X_{1}, X_{2}, \ldots$ være iid. stokastiske variabler, så kaldes
  \[
    \overline{X}_{n} = \frac{1}{n} \sum_{k=1}^n X_{k}
  \]
  for den $n$'te empiriske middelværdi.
\end{definition}

\begin{lemma} \label{lem:variansOgForventedeVærdiAfEmpiriskMiddelværdi}
  Lad $X_{1}, X_{2}, \ldots$ være iid. stokastiske variabler, med $E[X] = \mu$ og $\Var[X] = \sigma^{2}$, så er
  \begin{equation*}
    E[\overline{X}_{n}] = \mu \text{ og } \Var[\overline{X}_{n}] = \frac{\sigma^{2}}{n}
  \end{equation*}
\end{lemma}
\begin{proof}
  Resultatet om den forventede værdi følger umiddelbart af korollar \ref{cor:sumAfDiskreteVariable}, ved
  \begin{equation*}
    E[\overline{X}_{n}] = E \left[\sum^{n}_{k = 1} \frac{1}{n} X_{k}\right] = \frac{1}{n} \sum_{k=1}^{n} E[X_{k}] = \mu
  \end{equation*}

  Og variansen følger af korrollar \ref{cor:variansAfLinearKombinationAFUafhængigeVariable}, ved
  \begin{equation*}
    \Var[\overline{X}_{n}] = \Var \left[\sum^{n}_{k = 1} \frac{1}{n} X_{k}\right] = \frac{1}{n^{2}} \sum_{k=1}^{n} \Var[X_{k}] = \frac{\sigma}{n}
  \end{equation*}
\end{proof}

Loven om store tal beskriver, at ved en test med et stort antal forsøg vil den emperiske middelværdi, nærme sig den teoretiske middelværdi, jo flere forsøg der bliver foretaget.
\begin{thm} \label{thm:law_of_large_numbers}%theorem 4.1
    Lad $X_1, X_2, \dots$ være en følge af iid. stokastisk variabler, med middelværdien $\mu$, of lad $\overline{X}_{n}$ være den emperiske middelværdi. For hver $\varepsilon>0$ gælder at
    \begin{align*}
        P(|\overline{X}_{n}-\mu|>\varepsilon) \rightarrow 0 \text{ når } n \rightarrow \infty
    \end{align*}
\end{thm}
\begin{proof}
  Vi vil i dette bevis antage at $\sigma^{2} < \infty$. Anvend Chebyshews ulighed, sætning \ref{Thm:Chebyshewsulighed}, på $\overline{X}_{n}$, og lad $c=\varepsilon \sqrt{x}/\sigma$. Eftersom $E[\overline{X}_{n}]=\mu$ og $\Var[\overline{X}_{n}]=\sigma^2/n$, jævnfør lemma \ref{lem:variansOgForventedeVærdiAfEmpiriskMiddelværdi}, dermed giver det
    \begin{align*}
        P(|\overline{X}_{n}-\mu| > \varepsilon) \leq \frac{\sigma}{n\varepsilon^2}
    \end{align*}
  og resultatet følger umiddelbart heraf da $\frac{\sigma}{n\varepsilon^2} \rightarrow 0 \text{ når } n \rightarrow \infty.$
\end{proof}
\begin{remark}
  Det noteres at vi ovenfor kun har givet et bevis i tilfældet hvor $\sigma < \infty$, resultatet gælder også i det andet tilfælde, men beviset for dette udelades fra projektet.
\end{remark}
